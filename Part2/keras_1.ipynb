{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'D:\\temps\\mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'rb') as f:\n",
    "    (x_train, y_train), (x_val, y_val), (x_test, y_test) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((50000, 28, 28, 1))\n",
    "x_val = x_val.reshape((10000, 28, 28, 1))\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(categories=[range(10)], sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=[range(0, 10)],\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(np.array([0,1,2,3,4,5,6,7,8,9]).reshape(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encoder.transform(y_train.reshape(len(y_train), 1))\n",
    "y_val = encoder.transform(y_val.reshape(len(y_val), 1))\n",
    "y_test = encoder.transform(y_test.reshape(len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model with 1 conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1:\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.random.seed(0)\n",
    "        tf.set_random_seed(0)\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.history = None\n",
    "        \n",
    "        # Layer 1\n",
    "        self.model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=True,\n",
    "                              activation='relu', input_shape=(28,28,1), data_format='channels_last'))\n",
    "        self.model.add(MaxPooling2D(2, padding='valid', data_format='channels_last'))\n",
    "        \n",
    "        # Layer 4\n",
    "        self.model.add(Flatten())\n",
    "        \n",
    "        # Layer 5\n",
    "        self.model.add(Dense(10, use_bias=True, activation='softmax'))\n",
    "        \n",
    "        sgd = keras.optimizers.SGD(lr=0.01)\n",
    "        self.model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        self.model.summary()\n",
    "    \n",
    "    def train(self, x_tr, y_tr, x_v, y_v, ep, bs=32, early=10):\n",
    "        earlystop = EarlyStopping(patience=early)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                                    patience=2, \n",
    "                                                    verbose=1, \n",
    "                                                    factor=0.5, \n",
    "                                                    min_lr=0.00001)\n",
    "        callbacks = [earlystop, learning_rate_reduction]\n",
    "        \n",
    "        self.history = self.model.fit(x_tr, y_tr, validation_data=(x_v, y_v), epochs=ep, batch_size=bs,\n",
    "                                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 63,050\n",
      "Trainable params: 63,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod1 = CNN1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 0.5777 - acc: 0.8475 - val_loss: 0.3153 - val_acc: 0.9133\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.3282 - acc: 0.9041 - val_loss: 0.2864 - val_acc: 0.9181\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.3034 - acc: 0.9119 - val_loss: 0.2659 - val_acc: 0.9237\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.2846 - acc: 0.9170 - val_loss: 0.2633 - val_acc: 0.9214\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 0.2658 - acc: 0.9231 - val_loss: 0.2379 - val_acc: 0.9335\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.2456 - acc: 0.9288 - val_loss: 0.2167 - val_acc: 0.9399\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 0.2220 - acc: 0.9369 - val_loss: 0.2114 - val_acc: 0.9412\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.1997 - acc: 0.9433 - val_loss: 0.1793 - val_acc: 0.9512\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 0.1784 - acc: 0.9499 - val_loss: 0.1599 - val_acc: 0.9586\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.1598 - acc: 0.9554 - val_loss: 0.1430 - val_acc: 0.9637\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 0.1442 - acc: 0.9597 - val_loss: 0.1330 - val_acc: 0.9677\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.1313 - acc: 0.9633 - val_loss: 0.1264 - val_acc: 0.9662\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 0.1209 - acc: 0.9663 - val_loss: 0.1135 - val_acc: 0.9710\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.1124 - acc: 0.9688 - val_loss: 0.1116 - val_acc: 0.9718\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.1050 - acc: 0.9714 - val_loss: 0.1072 - val_acc: 0.9718\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.0989 - acc: 0.9728 - val_loss: 0.0994 - val_acc: 0.9742ETA: 0s - loss: 0.0\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 0.0938 - acc: 0.9741 - val_loss: 0.0952 - val_acc: 0.9758 5s - loss: 0. - ETA: 4 - ETA: 0s - loss: 0.0936 - acc: 0\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 0.0890 - acc: 0.9752 - val_loss: 0.0928 - val_acc: 0.9761\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 0.0851 - acc: 0.9762 - val_loss: 0.0904 - val_acc: 0.9769\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.0814 - acc: 0.9772 - val_loss: 0.0867 - val_acc: 0.9772\n"
     ]
    }
   ],
   "source": [
    "mod1.train(x_train, y_train, x_val, y_val, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 137us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07887579851225018, 0.9773]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1.model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model with 2 conv but fewer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.random.seed(0)\n",
    "        tf.set_random_seed(0)\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.history = None\n",
    "        \n",
    "        # Layer 1\n",
    "        self.model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=True,\n",
    "                              activation='relu', input_shape=(28,28,1), data_format='channels_last'))\n",
    "        self.model.add(MaxPooling2D(2, padding='valid', data_format='channels_last'))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=True,\n",
    "                              activation='relu', input_shape=(14,14,32), data_format='channels_last'))\n",
    "        self.model.add(MaxPooling2D(2, padding='valid', data_format='channels_last'))\n",
    "        \n",
    "        # Layer 4\n",
    "        self.model.add(Flatten())\n",
    "        \n",
    "        # Layer 5\n",
    "        self.model.add(Dense(10, use_bias=True, activation='softmax'))\n",
    "        \n",
    "        sgd = keras.optimizers.SGD(lr=0.01)\n",
    "        self.model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        self.model.summary()\n",
    "    \n",
    "    def train(self, x_tr, y_tr, x_v, y_v, ep, bs=32, early=10):\n",
    "        earlystop = EarlyStopping(patience=early)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                                    patience=2, \n",
    "                                                    verbose=1, \n",
    "                                                    factor=0.5, \n",
    "                                                    min_lr=0.00001)\n",
    "        callbacks = [earlystop, learning_rate_reduction]\n",
    "        \n",
    "        self.history = self.model.fit(x_tr, y_tr, validation_data=(x_v, y_v), epochs=ep, batch_size=bs,\n",
    "                                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                15690     \n",
      "=================================================================\n",
      "Total params: 25,258\n",
      "Trainable params: 25,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod2 = CNN2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 43s 862us/step - loss: 0.6073 - acc: 0.8229 - val_loss: 0.2720 - val_acc: 0.9178\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 44s 883us/step - loss: 0.2067 - acc: 0.9387 - val_loss: 0.1466 - val_acc: 0.9587\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 44s 873us/step - loss: 0.1394 - acc: 0.9584 - val_loss: 0.1082 - val_acc: 0.9701\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 44s 876us/step - loss: 0.1084 - acc: 0.9680 - val_loss: 0.0914 - val_acc: 0.9762\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 44s 882us/step - loss: 0.0922 - acc: 0.9729 - val_loss: 0.0827 - val_acc: 0.9762\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 0.0817 - acc: 0.9758 - val_loss: 0.0795 - val_acc: 0.9771\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 43s 868us/step - loss: 0.0733 - acc: 0.9780 - val_loss: 0.0720 - val_acc: 0.9797\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 43s 865us/step - loss: 0.0682 - acc: 0.9798 - val_loss: 0.0689 - val_acc: 0.9803\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 44s 876us/step - loss: 0.0637 - acc: 0.9808 - val_loss: 0.0702 - val_acc: 0.9794\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.0599 - acc: 0.9816 - val_loss: 0.0586 - val_acc: 0.9830\n"
     ]
    }
   ],
   "source": [
    "mod2.train(x_train, y_train, x_val, y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 288us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05285470188893378, 0.9832]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2.model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third model with 2 conv and 0.5M parameters (to compare with MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3:\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.random.seed(0)\n",
    "        tf.set_random_seed(0)\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.history = None\n",
    "        \n",
    "        # Layer 1\n",
    "        self.model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=True,\n",
    "                              activation='relu', input_shape=(28,28,1), data_format='channels_last'))\n",
    "        self.model.add(MaxPooling2D(2, padding='valid', data_format='channels_last'))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.model.add(Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=True,\n",
    "                              activation='relu', input_shape=(14,14,32), data_format='channels_last'))\n",
    "        self.model.add(MaxPooling2D(2, padding='valid', data_format='channels_last'))\n",
    "        \n",
    "        # Layer 4\n",
    "        self.model.add(Flatten())\n",
    "        \n",
    "        # Layer 5\n",
    "        self.model.add(Dense(512, use_bias=True, activation='relu'))\n",
    "        \n",
    "        # Layer 6\n",
    "        self.model.add(Dense(10, use_bias=True, activation='softmax'))\n",
    "        \n",
    "        sgd = keras.optimizers.SGD(lr=0.01)\n",
    "        self.model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        self.model.summary()\n",
    "    \n",
    "    def train(self, x_tr, y_tr, x_v, y_v, ep, bs=32, early=10):\n",
    "        earlystop = EarlyStopping(patience=early)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                                    patience=2, \n",
    "                                                    verbose=1, \n",
    "                                                    factor=0.5, \n",
    "                                                    min_lr=0.00001)\n",
    "        callbacks = [earlystop, learning_rate_reduction]\n",
    "        \n",
    "        self.history = self.model.fit(x_tr, y_tr, validation_data=(x_v, y_v), epochs=ep, batch_size=bs,\n",
    "                                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               803328    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 818,026\n",
      "Trainable params: 818,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod3 = CNN3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.5476 - acc: 0.8438 - val_loss: 0.2737 - val_acc: 0.9060\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.1596 - acc: 0.9510 - val_loss: 0.1227 - val_acc: 0.9640\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.1058 - acc: 0.9677 - val_loss: 0.0914 - val_acc: 0.9732\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0822 - acc: 0.9750 - val_loss: 0.0797 - val_acc: 0.9776\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0677 - acc: 0.9787 - val_loss: 0.0715 - val_acc: 0.9793\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0578 - acc: 0.9824 - val_loss: 0.0666 - val_acc: 0.9803\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0508 - acc: 0.9842 - val_loss: 0.0547 - val_acc: 0.9838\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0460 - acc: 0.9857 - val_loss: 0.0511 - val_acc: 0.9854\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0406 - acc: 0.9871 - val_loss: 0.0532 - val_acc: 0.9836\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0362 - acc: 0.9888 - val_loss: 0.0576 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0281 - acc: 0.9920 - val_loss: 0.0473 - val_acc: 0.9855\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0260 - acc: 0.9921 - val_loss: 0.0476 - val_acc: 0.9862\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0244 - acc: 0.9926 - val_loss: 0.0479 - val_acc: 0.9863\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0227 - acc: 0.9935 - val_loss: 0.0494 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0197 - acc: 0.9946 - val_loss: 0.0457 - val_acc: 0.9864\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0188 - acc: 0.9951 - val_loss: 0.0454 - val_acc: 0.9876\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0182 - acc: 0.9952 - val_loss: 0.0432 - val_acc: 0.9872\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0177 - acc: 0.9954 - val_loss: 0.0448 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0163 - acc: 0.9960 - val_loss: 0.0441 - val_acc: 0.9876\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0159 - acc: 0.9959 - val_loss: 0.0441 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0153 - acc: 0.9964 - val_loss: 0.0441 - val_acc: 0.9875\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0152 - acc: 0.9963 - val_loss: 0.0438 - val_acc: 0.9878\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0150 - acc: 0.9964 - val_loss: 0.0438 - val_acc: 0.9873\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0439 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.0146 - acc: 0.9965 - val_loss: 0.0439 - val_acc: 0.9875\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0145 - acc: 0.9966 - val_loss: 0.0439 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0143 - acc: 0.9967 - val_loss: 0.0439 - val_acc: 0.9875\n"
     ]
    }
   ],
   "source": [
    "mod3.train(x_train, y_train, x_val, y_val, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 328us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03355478632784216, 0.9886]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod3.model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth model with 2 conv and 0.5M parameters (to compare with MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN4:\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.random.seed(0)\n",
    "        tf.set_random_seed(0)\n",
    "        self.model = keras.models.Sequential()\n",
    "        self.history = None\n",
    "        \n",
    "        # Layer 1\n",
    "        self.model.add(Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=True,\n",
    "                              activation='relu', input_shape=(28,28,1), data_format='channels_last'))\n",
    "        self.model.add(MaxPooling2D(2, padding='valid', data_format='channels_last'))\n",
    "        \n",
    "        # Layer 2\n",
    "        self.model.add(Conv2D(128, kernel_size=3, strides=1, padding='same', use_bias=True,\n",
    "                              activation='relu', input_shape=(14,14,32), data_format='channels_last'))\n",
    "        self.model.add(MaxPooling2D(2, padding='valid', data_format='channels_last'))\n",
    "        \n",
    "        # Layer 4\n",
    "        self.model.add(Flatten())\n",
    "        \n",
    "        # Layer 5\n",
    "        self.model.add(Dense(128, use_bias=True, activation='relu'))\n",
    "        \n",
    "        # Layer 6\n",
    "        self.model.add(Dense(10, use_bias=True, activation='softmax'))\n",
    "        \n",
    "        sgd = keras.optimizers.SGD(lr=0.01)\n",
    "        self.model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        self.model.summary()\n",
    "    \n",
    "    def train(self, x_tr, y_tr, x_v, y_v, ep, bs=32, early=10):\n",
    "        earlystop = EarlyStopping(patience=early)\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                                    patience=2, \n",
    "                                                    verbose=1, \n",
    "                                                    factor=0.5, \n",
    "                                                    min_lr=0.00001)\n",
    "        callbacks = [earlystop, learning_rate_reduction]\n",
    "        \n",
    "        self.history = self.model.fit(x_tr, y_tr, validation_data=(x_v, y_v), epochs=ep, batch_size=bs,\n",
    "                                      callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 878,730\n",
      "Trainable params: 878,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod4 = CNN4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.6318 - acc: 0.8167 - val_loss: 0.2966 - val_acc: 0.9008\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.1685 - acc: 0.9488 - val_loss: 0.1262 - val_acc: 0.9647\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.1087 - acc: 0.9674 - val_loss: 0.1216 - val_acc: 0.9639\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 131s 3ms/step - loss: 0.0842 - acc: 0.9746 - val_loss: 0.0752 - val_acc: 0.9787\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.0694 - acc: 0.9786 - val_loss: 0.0701 - val_acc: 0.9796\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.0590 - acc: 0.9819 - val_loss: 0.0627 - val_acc: 0.9828\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 130s 3ms/step - loss: 0.0526 - acc: 0.9837 - val_loss: 0.0556 - val_acc: 0.9848\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.0474 - acc: 0.9856 - val_loss: 0.0507 - val_acc: 0.9866\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.0429 - acc: 0.9865 - val_loss: 0.0507 - val_acc: 0.9858\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 129s 3ms/step - loss: 0.0383 - acc: 0.9883 - val_loss: 0.0536 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n"
     ]
    }
   ],
   "source": [
    "mod4.train(x_train, y_train, x_val, y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 829us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04046680129289162, 0.9863]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod4.model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
